---
title: "Textmining"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(dplyr)
TexTest<-read.csv("/Users/mariyaoshyyko/Downloads/Data-mining/GitHub/Project_CVTDM/onlinedeliverydata copy.csv")
TexTest$Output <- recode(TexTest$Output, "Yes"=1, "No"=0)
positive=TexTest[TexTest$Output==1,]
negative=TexTest[TexTest$Output==0,]
```

# Positive
```{r}
library(dplyr)
library(tidytext)

positive_corp=Corpus(VectorSource(positive[,2]))
# Convert the text to lower case
positive_corp <- tm_map(positive_corp, content_transformer(tolower))
# Remove numbers
positive_corp <- tm_map(positive_corp, removeNumbers)
# Remove english common stopwords
positive_corp <- tm_map(positive_corp, removeWords, stopwords("english"))

# Remove punctuations
positive_corp <- tm_map(positive_corp, removePunctuation)
# Eliminate extra white spaces
positive_corp <- tm_map(positive_corp, stripWhitespace)
# Text stemming
positive_corp <- tm_map(positive_corp, stemDocument)

# Remove your own stop word

# specify your stopwords as a character vector
positive_corp <- tm_map(positive_corp, removeWords, c("nil")) 

tdm1 <- TermDocumentMatrix(positive_corp)
inspect(tdm1)
```


```{r}
library(wordcloud2)
library(wordcloud)
library(RColorBrewer)

matrix <- as.matrix(tdm1) 
words <- sort(rowSums(matrix),decreasing=TRUE) 
df_positive <- data.frame(word = names(words),freq=words)

set.seed(123) # for reproducibility 
wordcloud(words = df_positive$word, freq = df_positive$freq, min.freq = 3,max.words=200, random.order=FALSE, rot.per=0.35, colors=brewer.pal(8, "Dark2"))
```
# Negative

```{r}
negavive_corp=Corpus(VectorSource(negative[,2]))
# Convert the text to lower case
negavive_corp <- tm_map(negavive_corp, content_transformer(tolower))
# Remove numbers
negavive_corp <- tm_map(negavive_corp, removeNumbers)
# Remove english common stopwords
negavive_corp <- tm_map(negavive_corp, removeWords, stopwords("english"))

# Remove punctuations
negavive_corp <- tm_map(negavive_corp, removePunctuation)
# Eliminate extra white spaces
negavive_corp <- tm_map(negavive_corp, stripWhitespace)
# Text stemming
negavive_corp <- tm_map(negavive_corp, stemDocument)

# Remove your own stop word

# specify your stopwords as a character vector
negavive_corp <- tm_map(negavive_corp, removeWords, c("nil")) 

tdm2 <- TermDocumentMatrix(negavive_corp)
inspect(tdm2)
```

```{r}
matrix <- as.matrix(tdm2) 
words <- sort(rowSums(matrix),decreasing=TRUE) 
df_negative <- data.frame(word = names(words),freq=words)

set.seed(123) # for reproducibility 
wordcloud(words = df_negative$word, freq = df_negative$freq, min.freq = 1,max.words=200, random.order=FALSE, rot.per=0.35, colors=brewer.pal(8, "Dark2"))
```
# All reviews

## Word cloud
```{r}
corp_all=Corpus(VectorSource((TexTest[,2])))
# Convert the text to lower case
corp_all <- tm_map(corp_all, content_transformer(tolower))
# Remove numbers
corp_all <- tm_map(corp_all, removeNumbers)
# Remove english common stopwords
corp_all <- tm_map(corp_all, removeWords, stopwords("english"))

# Remove punctuations
corp_all <- tm_map(corp_all, removePunctuation)
# Eliminate extra white spaces
corp_all <- tm_map(corp_all, stripWhitespace)
# Text stemming
corp_all <- tm_map(corp_all, stemDocument)

# Remove your own stop word

# specify your stopwords as a character vector
corp_all <- tm_map(corp_all, removeWords, c("nil")) 

tdm3 <- TermDocumentMatrix(corp_all)
inspect(tdm3)
```

```{r}
matrix <- as.matrix(tdm3) 
words <- sort(rowSums(matrix),decreasing=TRUE) 
df_all <- data.frame(word = names(words),freq=words)

set.seed(123) # for reproducibility 
wordcloud(words = df_all$word, freq = df_all$freq, min.freq = 1,max.words=200, random.order=FALSE, rot.per=0.35, colors=brewer.pal(8, "Dark2"))
```


```{r}
# step 3: TF-IDF and latent semantic analysis
# compute TF-IDF
tfidf <- weightTfIdf(tdm3)
# extract (20) concepts
library(lsa)
lsa.tfidf <- lsa(tfidf, dim = 20)
# convert to data frame
words.df <- as.data.frame(as.matrix(lsa.tfidf$dk))
words.df$Output=TexTest$Output
View(words.df)
```

```{r}
library(randomForest)
set.seed(1)
rf <- randomForest(Output ~., data=words.df, ntree = 500, mtry = 4, nodesize = 5, importance = TRUE)
varImpPlot(rf, type = 1, cex=0.7)
subset.words=words.df[,-c(2,3,4)]
#tm.df=tSparse[,c(74,53,104,117,66,43,15,23,114,98,61,107,141,64,29,72, 183)]
```

```{r}
set.seed(1)
train_rows <- createDataPartition(words.df$Output, p = .5, list = FALSE)
train <- words.df[train_rows,]
valid_test <- words.df[-train_rows,]
set.seed(1)
valid_rows <- createDataPartition(valid_test$Output, p = .6, list = FALSE)
valid <- valid_test[valid_rows,]
test <- valid_test[-valid_rows,]
```

## Discriminant analysis

```{r}
set.seed(1)
train_rows1 <- createDataPartition(subset.words$Output, p = .5, list = FALSE)
train1 <- subset.words[train_rows1,]
valid_test1 <- subset.words[-train_rows1,]
set.seed(1)
valid_rows1 <- createDataPartition(valid_test1$Output, p = .6, list = FALSE)
valid1 <- valid_test1[valid_rows1,]
test1 <- valid_test1[-valid_rows1,]
```

```{r}
library(MASS)
library(DiscriMiner)
```

```{r}
model1 <- lda(Output~., data = train1)
model1
```


```{r}
pred.valid1=predict(model1,valid1[,-31])

cm.da.valid=confusionMatrix(as.factor(pred.valid1$class),as.factor(valid1$Output) ,positive = "1")
cm.da.valid
```



```{r}
da.pred.test1=predict(model1,test1[,-31])

cm.da.test=confusionMatrix(as.factor(da.pred.test1$class),as.factor(test1$Output) ,positive = "1")
cm.da.test
```

```{r}
fourfoldplot(cm.da.test$table)
```

## Classification Tree

#### Full-grown tree
```{r}
library(forecast)
library(caret)
library(Metrics)
library(dplyr)
library(reshape2)
library(scales)
library(rpart)

set.seed(1)
full_CT = rpart(Output ~ ., data = train, method = "class", cp=0, minbucket=1, minsplit = 1, xval =5)
length(full_CT$frame$var[full_CT$frame$var == "<leaf>"])
```

```{r}
library(ggplot2) 
library(cowplot)
library(rpart.plot)


rpart.plot(full_CT, type = 1, extra = 1, under = TRUE, split.font = 1, varlen = -10)
```

```{r}
row_minxerr=which.min(full_CT$cptable[,4])
cp_minxerr=full_CT$cptable[row_minxerr,1]
cp_minxerr
```
```{r}
minxerr=full_CT$cptable[row_minxerr,4]
xstd_minxerr=full_CT$cptable[row_minxerr,5]
cp_best_pruned_CT=minxerr+xstd_minxerr
cp_best_pruned_CT
```
```{r}
printcp(full_CT)[,4]
```
```{r}
cp_xerr=full_CT$cptable[5,1]
cp_xerr
```
```{r}
plotcp(full_CT) + 
  abline(v = row_minxerr, lty = "dashed")+
  abline(v = 5, lty = "dotted")
```

Letâ€™s prune 2 classification trees: first one with CP of 1 split(which has the lowest cross-validation error) and second with CP of 7 splits(best-pruned classification tree)

#### Pruned classification tree
```{r}
set.seed(1)
pruned_CT <- prune(full_CT, cp = cp_minxerr)
length(pruned_CT$frame$var[pruned_CT$frame$var == "<leaf>"])
```
```{r}
rpart.plot(pruned_CT, type = 1, extra = 1, under = TRUE, split.font = 1, varlen = -10)
```

```{r}
pred_valid_pruned_CT= predict(pruned_CT, valid, type="class")

valid$Output=as.factor(valid$Output)
CT_cm_valid=confusionMatrix(pred_valid_pruned_CT, valid$Output , positive = "1")
CT_cm_valid
```

```{r}
fourfoldplot(confusionMatrix(pred_valid_pruned_CT, valid$Output , positive = "1")$table)
```


```{r}
pred_test_pruned_CT= predict(pruned_CT, test, type="class")

test$Output=as.factor(test$Output)
CT_cm_valid=confusionMatrix(pred_test_pruned_CT, test$Output , positive = "1")
CT_cm_valid
```

```{r}
fourfoldplot(confusionMatrix(pred_test_pruned_CT, test$Output , positive = "1")$table)
```


#### Best pruned classification tree

```{r}
best_pruned_CT <- prune(full_CT,cp = cp_xerr)
length(best_pruned_CT$frame$var[best_pruned_CT$frame$var == "<leaf>"])
```

```{r}
rpart.plot(best_pruned_CT, type = 1, extra = 1, under = TRUE, split.font = 1, varlen = -10)
```

```{r}
pred_valid_best_pruned_CT= predict(best_pruned_CT, valid, type="class")

valid$Output=as.factor(valid$Output)
CT_cm_valid=confusionMatrix(pred_valid_best_pruned_CT, valid$Output , positive = "1")
CT_cm_valid
```

```{r}
fourfoldplot(confusionMatrix(pred_valid_best_pruned_CT, valid$Output , positive = "1")$table)
```


```{r}
pred_test_best_pruned_CT= predict(best_pruned_CT, test, type="class")

test$Output=as.factor(test$Output)
CT_cm_test=confusionMatrix(pred_test_best_pruned_CT, test$Output , positive = "1")
CT_cm_test
```

```{r}
fourfoldplot(confusionMatrix(pred_test_best_pruned_CT, test$Output , positive = "1")$table)
```

## Boosted

```{r}
library(cowplot)
library(caret)
library(rpart)
library(gains)
library(adabag)
library(randomForest)
library(reshape2)
```


```{r}
set.seed(1)
train$Output=as.factor(train$Output)
boost <- boosting(Output ~ ., data = train)
```


```{r}
pred_boost_valid <- predict(boost, valid)
boost_valid.cm = confusionMatrix(as.factor(pred_boost_valid$class), valid$Output, positive = "1")

boost_valid.cm
```

```{r}
pred_boost_test <- predict(boost, test)
boost_test.cm = confusionMatrix(as.factor(pred_boost_test$class), (test$Output),positive = "1")

boost_test.cm
```

## Bagged

```{r}
set.seed(1)
bagt <- bagging(Output ~ ., data = train)
```


```{r}
pred <- predict(bagt, valid)
bag_valid.cm = confusionMatrix(as.factor(pred$class), valid$Output,positive = "1")

bag_valid.cm
```

```{r}
pred <- predict(bagt, test)
bag_test.cm = confusionMatrix(as.factor(pred$class), test$Output,positive = "1")

bag_test.cm
```

## Random

```{r}
set.seed(1)
rf <- randomForest(Output ~ ., data = train, mtry=4, importance = T)

pred <- predict(rf, valid)


rf_valid.cm = confusionMatrix(pred, as.factor(valid$Output) ,positive = "1")

rf_valid.cm
```

```{r}
pred <- predict(rf, test)

rf_test.cm = confusionMatrix(as.factor(pred), as.factor(test$Output), positive = "1")

rf_test.cm
```


## Naive Bayes

```{r}
library(e1071)

naivebayes <- naiveBayes(Output ~., data=train)
#naivebayes
pred_valid.nb <- predict(naivebayes, newdata = valid)
pred_test.nb <- predict(naivebayes, newdata = test)

nb.valid.balanced.acc=confusionMatrix(pred_valid.nb, valid$Output, positive = "1")$byClass["Balanced Accuracy"]
nb.test.balanced.acc=confusionMatrix(pred_test.nb, test$Output,positive = "1")$byClass["Balanced Accuracy"]
confusionMatrix(pred_valid.nb, valid$Output, positive = "1")$byClass["F1"]
confusionMatrix(pred_test.nb, test$Output, positive = "1")$byClass["F1"]
```

## Logistic Regression

```{r}
log.reg <- glm(Output ~ ., data = train, family = "binomial")
options(scipen=999)
summary(log.reg)
pred_valid.log <- predict(log.reg, valid, type = "response")
pred_test.log <- predict(log.reg, test, type = "response")

lr.valid.balanced.acc=confusionMatrix(as.factor(ifelse(pred_valid.log > 0.5, 1, 0)), valid$Output, positive = "1")$byClass["Balanced Accuracy"]
lr.test.balanced.acc=confusionMatrix(as.factor(ifelse(pred_test.log > 0.5, 1, 0)), test$Output, positive = "1")$byClass["Balanced Accuracy"]
confusionMatrix(as.factor(ifelse(pred_valid.log > 0.5, 1, 0)), valid$Output, positive = "1")$byClass["F1"]
confusionMatrix(as.factor(ifelse(pred_test.log > 0.5, 1, 0)), test$Output, positive = "1")$byClass["F1"]
```



## Comparison of the methods

```{r}
F1 <- data.frame("model" = c("naive bayes","logistic regression","discriminant analysis","k-NN","neural nets", "classification tree","boosted", "bagged", "random"),
                 
                 "valid"=c(nb.valid.balanced.acc, lr.valid.balanced.acc, cm.da.valid$byClass["F1"], confusionMatrix(knn1, valid.st[,16], positive = "1")$byClass["F1"] , cm.nn1.valid$byClass["F1"], CT_cm_valid$byClass["F1"], boost_valid.cm$byClass["F1"], bag_valid.cm$byClass["F1"], rf_valid.cm$byClass["F1"]),
                 
                 "test"=c(nb.test.balanced.acc, lr.test.balanced.acc, cm.da.test$byClass["F1"], confusionMatrix(knn1.test, test.st[,16], positive = "1")$byClass["F1"], cm.nn1.test$byClass["F1"], CT_cm_test$byClass["F1"], boost_test.cm$byClass["F1"], bag_test.cm$byClass["F1"], rf_test.cm$byClass["F1"]))
F1
```
### Result
```{r}
balanced_accuracy <- data.frame("model" = c("naive bayes","logistic regression","discriminant analysis","k-NN","neural nets", "classification tree","boosted", "bagged", "random"),
                                
                                "valid"=c(nb.valid.balanced.acc, lr.valid.balanced.acc, cm.da.valid$byClass["Balanced Accuracy"], confusionMatrix(knn1, valid.st[,16], positive = "1")$byClass["Balanced Accuracy"] , cm.nn1.valid$byClass["Balanced Accuracy"], CT_cm_valid$byClass["Balanced Accuracy"], boost_valid.cm$byClass["Balanced Accuracy"], bag_valid.cm$byClass["Balanced Accuracy"], rf_valid.cm$byClass["Balanced Accuracy"]),
                                
                                "test"=c(nb.test.balanced.acc, lr.test.balanced.acc, cm.da.test$byClass["Balanced Accuracy"], confusionMatrix(knn1.test, test.st[,16], positive = "1")$byClass["Balanced Accuracy"], cm.nn1.test$byClass["Balanced Accuracy"], CT_cm_test$byClass["Balanced Accuracy"], boost_test.cm$byClass["Balanced Accuracy"], bag_test.cm$byClass["Balanced Accuracy"], rf_test.cm$byClass["Balanced Accuracy"]))
balanced_accuracy
```





