---
title: 'Project'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
rm(list = ls()) 
cat("\014")
```

```{r}
library(ggplot2)
library(reshape)
library(reshape2)
library(dplyr)
library(naniar)
library(ggcorrplot)
library(caret)
library(gridExtra)
library(DiscriMiner)
library(MASS)
library(corrr)
library(rpart)
library(rpart.plot)
library(e1071)
library(randomForest)
library(FNN)
library(neuralnet)
library(nnet)
library(NeuralNetTools)
library(boot)
library(plyr)
library(forecast)
library(Metrics)
library(scales)
library(cowplot)
library(gains)
library(adabag)

```

# Exploratory analysis

```{r}
df <- read.csv(file = "/Users/mariyaoshyyko/Downloads/Data-mining/GitHub/Project_CVTDM/onlinedeliverydata.csv")
#df <- read.csv("onlinedeliverydata.csv", header = TRUE, sep = ",")
df <- df[,-c(8,9,10)]# these variables were from the beginning not useful for the purpose of our analysis
str(df)
attach(df)
```

```{r}
summary(df)
```

### Continuous variables exploration

```{r}
boxplot_exp<-ggplot(df) +
  geom_boxplot(aes(x=Age), fill="white") +
  labs(title="Range of Age values")+
  theme_minimal()+
  theme(plot.title = element_text(face="bold"))
median=median(df[,1])
mean=mean(df[,1])
hist_exp<-ggplot(df) +
  geom_histogram(aes(x=Age), bins=10, fill = "slategray1",color="grey") +
  geom_vline (aes(xintercept=median,col="median"))+
  geom_vline(aes(xintercept=mean,col="mean"))+
  labs(title="Distribution of Age",color="")+
  theme_minimal()+
  theme(plot.title = element_text(face="bold"))
grid.arrange(boxplot_exp, hist_exp, ncol=2)
```

```{r}
boxplot_exp<-ggplot(df) +
  geom_boxplot(aes(x=Family.size), fill="white") +
  labs(title="Range of Family.size values")+
  theme_minimal()+
  theme(plot.title = element_text(face="bold"))
median=median(df[,7])
mean=mean(df[,7])
hist_exp<-ggplot(df) +
  geom_histogram(aes(x=Family.size), bins=10, fill = "slategray1",color="grey") +
  geom_vline (aes(xintercept=median,col="median"))+
  geom_vline(aes(xintercept=mean,col="mean"))+
  labs(title="Distribution of Family.size",color="")+
  theme_minimal()+
  theme(plot.title = element_text(face="bold"))
grid.arrange(boxplot_exp, hist_exp, ncol=2)
```

```{r}
boxplot_exp<-ggplot(df) +
  geom_boxplot(aes(x=Maximum.wait.time ), fill="white") +
  labs(title="Range of Maximum.wait.time values")+
  theme_minimal()+
  theme(plot.title = element_text(face="bold"))
median=median(df[,36])
mean=mean(df[,36])
hist_exp<-ggplot(df) +
  geom_histogram(aes(x=Maximum.wait.time), bins=10, fill = "slategray1",color="grey") +
  geom_vline (aes(xintercept=median,col="median"))+
  geom_vline(aes(xintercept=mean,col="mean"))+
  labs(title="Distribution of Maximum.wait.time",color="")+
  theme_minimal()+
  theme(plot.title = element_text(face="bold"))
grid.arrange(boxplot_exp, hist_exp, ncol=2)
```

### Categorical variables vizualization

```{r}
subset.class.category=df[,c(2:6,14:50)]

for (i in c(2:6,8:50)) {

explore1=df[,c(i, 51)]
explore1=melt(explore1, id="Output")
explore.cast=dcast(explore1, Output~value, fun.aggregate=length)
explore2=melt(explore.cast, id="Output")

explore2$Output=as.factor(explore2$Output)

print(ggplot(explore2) + 
  scale_fill_brewer(palette="Pastel2")+
  geom_col(aes(x=explore2$variable, y=explore2$value, fill=explore2$Output),  position = "dodge")+
  labs(title=names(df)[c(i)], x="", y="value",fill="Output:",color=""))+
  theme_minimal()
}
```
### Recoding
```{r}
df1 <- df[,-52]# remove reviews as it's not useful in this part of analysis but we'll use it later

for (i in c(14:33,37:41)) {
  df1[,i] <- recode(df1[,i], "Strongly Agree"=5, "Agree"=4,"Neutral"=3,"Disagree"=2,"Strongly Disagree"=1)
}
gg_miss_var(df1[,c(14:33,37:41)], show_pct = TRUE)

df1$Output <- recode(df1$Output, "Yes"=1, "No"=0)
gg_miss_var(df[,50:51], show_pct = TRUE)

levels(as.factor(df1[,5]))
df1$Monthly.Income=recode(df$Monthly.Income, "10001 to 25000"=17500.5, "25001 to 50000"=37500, "Below Rs.10000" = 10000, "More than 50000"=50000, "No Income"=0 )


for (i in c(43:50)) {
  df1[,i] <- recode(df1[,i], "Important"=4, "Moderately Important"=3, "Slightly Important"=2, "Unimportant"=1, "Very Important"=5)
}
gg_miss_var(df1[,43:50], show_pct = TRUE)

for (i in c(34,42)) {
  df1[,i] <- recode(df1[,i], "Maybe"=2, "No"=1, "Yes"=3)
}
gg_miss_var(df1[,c(34,42)], show_pct = TRUE)

df1$Gender <- recode(df1$Gender, "Female"=1, "Male"=0)
gg_miss_var(df1[,1:2], show_pct = TRUE)
```

```{r}
df1=df1[,-c(8:13)]# delete predictors suitable for customer segmentation
```

### Correlation matrix
```{r fig.height=6, fig.width=6}
numeric.df=df1[,-c(3,4,6,29)]

corr <- round(cor(numeric.df,method="spearman"), 3)
ggcorrplot(corr, hc.order = TRUE,
   outline.col = "white",
   ggtheme = ggplot2::theme_gray,
   colors = c("#6D9EC1", "white", "#E46726"))
```
### VIF
```{r}
VIF = function(matx, y){
  #
  fit.dat = data.frame(y=y, matx)
  fit.lm = lm(y ~ . , data=fit.dat)
  #
  vifs = vif.lm.car(fit.lm)
  #
  cat("\n")
  print(signif(vifs))
  cat("\n  Mean:", format(signif(mean(vifs))), "\n\n")
}
vif.lm.car = function(mod, ...) 
{
  # Calculates variance-inflation and generalized variance-inflation factors for linear and generalized linear models. 
  #
  # "vif" function from package "car" (Version 2.0-12)
  # Source: http://cran.r-project.org/web/packages/car/
  # R documentation: ?car::vif
  if (any(is.na(coef(mod))))
    stop("there are aliased coefficients in the model")
  v <- vcov(mod)
  assign <- attributes(model.matrix(mod))$assign
  if (names(coefficients(mod)[1]) == "(Intercept)") {
    v <- v[-1, -1]
    assign <- assign[-1]
  }
  else warning("No intercept: vifs may not be sensible.")
  terms <- labels(terms(mod))
  n.terms <- length(terms)
  if (n.terms < 2) 
    stop("model contains fewer than 2 terms")
  R <- cov2cor(v)
  detR <- det(R)
  result <- matrix(0, n.terms, 3)
  rownames(result) <- terms
  colnames(result) <- c("GVIF", "Df", "GVIF^(1/(2*Df))")
  for (term in 1:n.terms) {
    subs <- which(assign == term)
    result[term, 1] <- det(as.matrix(R[subs, subs])) * det(as.matrix(R[-subs, -subs]))/detR
    result[term, 2] <- length(subs)
  }
  if (all(result[, 2] == 1)) 
    result <- result[, 1]
  else result[, 3] <- result[, 1]^(1/(2 * result[, 2]))
  result
}

VIF(numeric.df[,-41], numeric.df[,41])
```

### Variable selection

#### Discriminant analysis
```{r}
df1$Marital.Status =as.factor(df1$Marital.Status)
df1$Occupation=as.factor(df1$Occupation)
df1$Educational.Qualifications=as.factor(df1$Educational.Qualifications)
df1$Order.Time=as.factor(df1$Order.Time)

dummies=dummyVars(~., data=df1)
df_dummy=as.data.frame(predict(dummies, newdata=df1))

df_dummy=df_dummy[,-c(4,7,15,38)]
str(df_dummy)
```

```{r}

norm.values.da = preProcess(df_dummy[,c(1,8,37)], method=c("center","scale"))
norm.da.df = predict(norm.values.da, df_dummy)

model1 <- lda(Output~., data = norm.da.df)
model1

norm.da.df$Output=as.factor(norm.da.df$Output)
var.selct.df1 <- linDA(norm.da.df[,-c(52)], norm.da.df[,52])
scores=var.selct.df1$functions 
score=as.data.frame(scores)
colnames(score)=c("No.score","Yes.score")
attach(score)
new.score=score[order(-Yes.score),]
new.score
detach(score)
```

```{r}
norm.values.da = preProcess(df_dummy[,-c(2:7,9:12,35,36,52)], method=c("center","scale"))
norm.da.df = predict(norm.values.da, df_dummy)


model1 <- lda(Output~., data = norm.da.df)
model1

norm.da.df$Output=as.factor(norm.da.df$Output)
var.selct.df1 <- linDA(norm.da.df[,-c(52)], norm.da.df[,52])
scores=var.selct.df1$functions 
score=as.data.frame(scores)
colnames(score)=c("No.score","Yes.score")
attach(score)
new.score=score[order(-Yes.score),]
new.score
detach(score)
```

```{r}
df_da <- df1[,c(1,2,3,4,6,9,10,12,15,16,17,19,21,22,23,26,27,29,30,31,33,34,36,37,38,40,42,43,45)]
```

#### Logistic regression

```{r}
logit.df=df1
for (i in c(3:4,6,8:13,35)){
  logit.df[,i]=as.factor(logit.df[,i])
}
str(logit.df)

set.seed(1)

train.index <- sample(rownames(logit.df), dim(logit.df)[1]*0.5)
valid.index <- sample(setdiff(rownames(logit.df), train.index), dim(logit.df)[1]*0.3)
test.index <- setdiff(rownames(logit.df), union(train.index, valid.index))

train.df <- logit.df[train.index, ]
valid.df <- logit.df[valid.index, ]
test.df <- logit.df[test.index, ]
```

```{r}
logit_reg <- glm(Output ~ ., data = train.df, family = "binomial")
options(scipen=999)
summary(logit_reg)
```

```{r}
forward <- step(logit_reg,direction ="forward")
summary(forward)
```

```{r}
df1$Output <- as.factor(df1$Output)
str(df1)
variables <- as.data.frame(colnames(df1)) 
```


#### Classifcation tree

```{r fig.height=9, fig.width=10}
tree <- rpart(Output ~., data=df1, method="class", cp=0, minsplit=1, minbucket=1)
rpart.plot(tree, cex=0.8)
```

```{r}
df_classtree <- df1[,c(1,2,3,5,6,8,9,10,14,15,19,21,22,24,25,26,27,31,33,34,36,28,40,45)]
```

#### Random Forest

```{r}
rf <- randomForest(Output ~., data=df1, ntree = 500, mtry = 4, nodesize = 5, importance = TRUE)
varImpPlot(rf, type = 1, cex=0.7)
```

```{r}
df_randomf <- df1[,c(1,3,4,5,6,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,27,30,36,38,39,40,41,45)]
```


#### Naive Bayes (fitting to 3 subsets)

```{r}
str(df_da)
prop.table(table(df1$Output))

set.seed(1)
train.rows <- createDataPartition(df1$Output, p = .6, list = FALSE)

train1 <- df_classtree[train.rows,]
valid1 <- df_classtree[-train.rows,]

train2 <- df_randomf[train.rows,]
valid2 <- df_randomf[-train.rows,]

train3 <- df_da[train.rows,]
valid3 <- df_da[-train.rows,]

print(table(train1$Output) / table(df1$Output)) #Training set partition
print(table(valid1$Output) / table(df1$Output)) #Validation set partition
```

```{r}
naivebayes1 <- naiveBayes(Output ~., data=train1)
pred1 <- predict(naivebayes1, newdata = valid1)

naivebayes2 <- naiveBayes(Output ~., data=train2)
pred2 <- predict(naivebayes2, newdata = valid2)

naivebayes3 <- naiveBayes(Output ~., data=train3)
pred3 <- predict(naivebayes3, newdata = valid3)

accuracy <- data.frame(model_naiveBayes = c("class tree", "random forest", "discriminant analysis"))

valid3$Output=as.factor(valid3$Output)

accuracy$Balanced_Accuracy <- c(confusionMatrix(pred1, valid1$Output)$byClass["Balanced Accuracy"], confusionMatrix(pred2, valid2$Output)$byClass["Balanced Accuracy"], confusionMatrix(pred3, valid3$Output)$byClass["Balanced Accuracy"])

accuracy$F1 <- c(confusionMatrix(pred1, valid1$Output)$byClass["F1"], confusionMatrix(pred2, valid2$Output)$byClass["F1"], confusionMatrix(pred3, valid3$Output)$byClass["F1"])
accuracy
```

#### Logistic regression (fitting to 3 subsets)

```{r}
logit1 <- glm(Output ~ ., data = train1, family = "binomial")
#summary(logit1)
log.pred1 = predict(logit1, valid1[,-45], type = "response")


logit2 <- glm(Output ~ ., data = train2, family = "binomial")
#summary(logit2)
log.pred2 = predict(logit2, valid2[,-45], type = "response")

logit3 <- glm(Output ~ ., data = train3, family = "binomial")
#summary(logit3)
log.pred3 = predict(logit3, valid3[,-45], type = "response")

accuracy1 <- data.frame(model_logit=c("class tree", "random forest", "discriminant analysis"))

accuracy1$Balanced_Accuracy <- c(confusionMatrix(as.factor(ifelse(log.pred1 > 0.5, 1, 0)), valid1$Output)$byClass["Balanced Accuracy"], confusionMatrix(as.factor(ifelse(log.pred2 > 0.5, 1, 0)), valid2$Output)$byClass["Balanced Accuracy"], confusionMatrix(as.factor(ifelse(log.pred3 > 0.5, 1, 0)), valid3$Output)$byClass["Balanced Accuracy"])

accuracy1$F1 <- c(confusionMatrix(as.factor(ifelse(log.pred1 > 0.5, 1, 0)), valid1$Output)$byClass["F1"], confusionMatrix(as.factor(ifelse(log.pred2 > 0.5, 1, 0)), valid2$Output)$byClass["F1"], confusionMatrix(as.factor(ifelse(log.pred3 > 0.5, 1, 0)), valid3$Output)$byClass["F1"])
accuracy1
```

#### Classification Tree (fitting to 3 subsets)

```{r}
set.seed(1)
tree1 <- rpart(Output ~., data=train1, method="class", cp=0, minsplit=1, minbucket=1, xval=5)
pruned1 <- prune(tree1, cp = tree1$cptable[which.min(tree1$cptable[,"xerror"]),"CP"])
tree.pred1 <- predict(pruned1, valid1, type="class")

set.seed(1)
tree2 <- rpart(Output ~., data=train2, method="class", cp=0, minsplit=1, minbucket=1, xval=5)
pruned2 <- prune(tree2, cp = tree2$cptable[which.min(tree2$cptable[,"xerror"]),"CP"])
tree.pred2 <- predict(pruned2, valid2, type="class")

set.seed(1)
tree3 <- rpart(Output ~., data=train3, method="class", cp=0, minsplit=1, minbucket=1, xval=5)
pruned3 <- prune(tree3, cp = tree3$cptable[which.min(tree3$cptable[,"xerror"]),"CP"])
tree.pred3 <- predict(pruned3, valid3, type="class")

accuracy2 <- data.frame(model_class.tree=c("class tree", "random forest", "discriminant analysis"))

accuracy2$Balanced_Accuracy <- c(confusionMatrix(tree.pred1, valid1$Output, positive="1")$byClass["Balanced Accuracy"], confusionMatrix(tree.pred2, valid2$Output, positive="1")$byClass["Balanced Accuracy"], confusionMatrix(tree.pred3, valid3$Output, positive="1")$byClass["Balanced Accuracy"])

accuracy2$F1 <- c(confusionMatrix(tree.pred1, valid1$Output, positive="1")$byClass["F1"], confusionMatrix(tree.pred2, valid2$Output, positive="1")$byClass["F1"], confusionMatrix(tree.pred3, valid3$Output, positive="1")$byClass["F1"])
accuracy2
```

# Classification

# {.tabset .tabset-fade .tabset-pills}

## Subset of 30 predictors

```{r message=FALSE, warning=FALSE}
df2 = df1[,c(8,	9,	12,	10,	21,	11,	1	,30	,17,	14,	13,	39,	4,27, 3,23,40,20, 15, 5,16,18,38,19,26,25,36,24,33,34, 45)]

str(df2)
```

#### Dummies

```{r message=FALSE, warning=FALSE}
df2$Occupation=as.factor(df2$Occupation)
df2$Marital.Status =as.factor(df2$Marital.Status)

dummies=dummyVars(~., data=df2[,-31])
df.dummy=as.data.frame(predict(dummies, newdata=df2))

df.dummy=df.dummy[,-c(14,19)]
str(df.dummy)
```

```{r message=FALSE, warning=FALSE}
df.dummy$Output <- as.factor(df2$Output)
str(df.dummy)
```

#### Partitioning

```{r message=FALSE, warning=FALSE}
set.seed(1)
train_rows <- createDataPartition(df2$Output, p = .5, list = FALSE)
train <- df2[train_rows,]
valid_test <- df2[-train_rows,]
set.seed(1)
valid_rows <- createDataPartition(valid_test$Output, p = .6, list = FALSE)
valid <- valid_test[valid_rows,]
test <- valid_test[-valid_rows,]
```

```{r message=FALSE, warning=FALSE}
set.seed(1)
train_rows1 <- createDataPartition(df.dummy$Output, p = .5, list = FALSE)
train.dummy <- df.dummy[train_rows1,]
valid_test.dummy <- df.dummy[-train_rows1,]
set.seed(1)
valid_rows1 <- createDataPartition(valid_test.dummy$Output, p = .6, list = FALSE)
valid.dummy <- valid_test.dummy[valid_rows1,]
test.dummy <- valid_test.dummy[-valid_rows1,]
```


```{r message=FALSE, warning=FALSE}
print(table(train$Output) / table(df2$Output)) #Training set partition
print(table(valid$Output) / table(df2$Output)) #Validation set partition
print(table(test$Output) / table(df2$Output)) #Test set partition
```

#### Naive Bayes

```{r message=FALSE, warning=FALSE}
naivebayes <- naiveBayes(Output ~., data=train)
naivebayes
```

```{r message=FALSE, warning=FALSE}
pred_valid.nb <- predict(naivebayes, newdata = valid)
pred_test.nb <- predict(naivebayes, newdata = test)
nb.valid.balanced.acc=confusionMatrix(pred_valid.nb, valid$Output, positive = "1")$byClass["Balanced Accuracy"]
nb.test.balanced.acc=confusionMatrix(pred_test.nb, test$Output,positive = "1")$byClass["Balanced Accuracy"]
confusionMatrix(pred_valid.nb, valid$Output, positive = "1")
fourfoldplot(confusionMatrix(pred_valid.nb, valid$Output, positive = "1")$table)
```

```{r message=FALSE, warning=FALSE}
confusionMatrix(pred_test.nb, test$Output, positive = "1")
fourfoldplot(confusionMatrix(pred_test.nb, test$Output, positive = "1")$table)
```

#### Logistic Regression

```{r}
log.reg <- glm(Output ~ ., data = train, family = "binomial")
options(scipen=999)
summary(log.reg)
```

```{r}
pred_valid.log <- predict(log.reg, valid, type = "response")
pred_test.log <- predict(log.reg, test, type = "response")

lr.valid.balanced.acc=confusionMatrix(as.factor(ifelse(pred_valid.log > 0.5, 1, 0)), valid$Output, positive = "1")$byClass["Balanced Accuracy"]
lr.test.balanced.acc=confusionMatrix(as.factor(ifelse(pred_test.log > 0.5, 1, 0)), test$Output, positive = "1")$byClass["Balanced Accuracy"]
confusionMatrix(as.factor(ifelse(pred_valid.log > 0.5, 1, 0)), valid$Output, positive = "1")
fourfoldplot(confusionMatrix(as.factor(ifelse(pred_valid.log > 0.5, 1, 0)), valid$Output, positive = "1")$table)
```

```{r}
confusionMatrix(as.factor(ifelse(pred_test.log > 0.5, 1, 0)), test$Output, positive = "1")
fourfoldplot(confusionMatrix(as.factor(ifelse(pred_test.log > 0.5, 1, 0)), test$Output, positive = "1")$table)
```

#### Discriminant analysis

```{r}
model1 <- lda(Output~., data = train)
model1
```

```{r}
pred.valid=predict(model1,valid[,-31])

cm.da.valid=confusionMatrix(as.factor(pred.valid$class),as.factor(valid$Output) ,positive = "1")
cm.da.valid

fourfoldplot(cm.da.valid$table)
```

```{r}
da.pred.test=predict(model1,test[,-31])

cm.da.test=confusionMatrix(as.factor(da.pred.test$class),as.factor(test$Output) ,positive = "1")
cm.da.test

fourfoldplot(cm.da.test$table)
```

#### KNN

```{r}
train.st <- train.dummy
valid.st <- valid.dummy
test.st <- test.dummy

standard.values = preProcess(train.dummy[,c(1:12,16,19:33)], method=c("center", "scale"))
train.st[,c(1:12,16,19:33)] <- predict(standard.values, train.dummy[,c(1:12,16,19:33)])
valid.st[,c(1:12,16,19:33)] <- predict(standard.values, valid.dummy[,c(1:12,16,19:33)])
test.st[,c(1:12,16,19:33)] <- predict(standard.values, test.dummy[,c(1:12,16,19:33)])

str(train.st)
```

```{r}
metrics <- data.frame(k=seq(1, 30, 1), balanced_accuracy = rep(0, 30), F1_score = rep(0, 30))

 for(i in 1:30) {
  knn <- knn(train=train.st[,-34], test=valid.st[,-34], cl=train.st[,34], k=i)
  metrics[i, 2] = confusionMatrix(knn, valid.st[,34], positive = "1")$byClass["Balanced Accuracy"]
  metrics[i, 3] = confusionMatrix(knn, valid.st[,34], positive = "1")$byClass["F1"]
 }

ggplot(data= metrics)+ 
  geom_line(aes(x=k, y=balanced_accuracy))+
  theme_bw()
ggplot(data= metrics)+ 
  geom_line(aes(x=k, y=F1_score))+
  theme_bw()

which.max(metrics$balanced_accuracy)
which.max(metrics$F1_score)
```

```{r}
knn2 <- knn(train=train.st[,-34], test=valid.st[,-34], cl=train.st[,34], k=2)
knn14 <- knn(train=train.st[,-34], test=valid.st[,-34], cl=train.st[,34], k=14)

knn2.test <- knn(train=train.st[,-34], test=test.st[,-34], cl=train.st[,34], k=2)
knn14.test <- knn(train=train.st[,-34], test=test.st[,-34], cl=train.st[,34], k=14)

knn.acc <- data.frame(df=c("valid_knn2","test_knn2","valid_knn14","test_knn14"))
knn.acc$Balanced_Accuracy <- c(confusionMatrix(knn2, valid.st[,34], positive = "1")$byClass["Balanced Accuracy"], confusionMatrix(knn2.test, test.st[,34], positive = "1")$byClass["Balanced Accuracy"],confusionMatrix(knn14, valid.st[,34], positive = "1")$byClass["Balanced Accuracy"], confusionMatrix(knn14.test, test.st[,34], positive = "1")$byClass["Balanced Accuracy"])

knn.acc$F1 <- c(confusionMatrix(knn2, valid.st[,34], positive = "1")$byClass["F1"], confusionMatrix(knn2.test, test.st[,34], positive = "1")$byClass["F1"],confusionMatrix(knn14, valid.st[,34], positive = "1")$byClass["F1"], confusionMatrix(knn14.test, test.st[,34], positive = "1")$byClass["F1"])
knn.acc
```

#### Neural Nets

```{r}
train.dummy.scale=train.dummy
valid.dummy.scale=valid.dummy
test.dummy.scale=test.dummy

vars = c(1:12,16,19:33)
norm.values <- preProcess(train.dummy[, vars], method="range") 

train.dummy.scale[,vars] = predict(norm.values, train.dummy[,vars])
valid.dummy.scale[,vars] = predict(norm.values, valid.dummy[,vars])
test.dummy.scale[,vars] = predict(norm.values, test.dummy[,vars])

scale_back_min_max_score <- function(x_) {
  min_x = min(train.dummy$Output)
  max_x = max(train.dummy$Output)
  x = sapply(x_, function(x__) x__*(max_x - min_x) + min_x)
  return(x)
}
```

##### 1 layer 5 nodes
```{r}
set.seed(1)

names(train.dummy.scale)[names(train.dummy.scale) == "Occupation.Self Employeed"] <- "Occupation.SelfEmployeed"

NN_1_5 <- neuralnet(Output ~. , train.dummy.scale, linear.output = FALSE, hidden = 5)
plot(NN_1_5)
```

```{r}
nn1.predict.valid <-  neuralnet::compute(NN_1_5, valid.dummy.scale[,-34])
predicted.class=apply(nn1.predict.valid$net.result,1,which.max)-1

confusionMatrix(as.factor(predicted.class), valid.dummy.scale$Output, positive = "1")
cm.nn1.valid=confusionMatrix(as.factor(predicted.class), valid.dummy.scale$Output, positive = "1")
fourfoldplot(cm.nn1.valid$table)
```

```{r}
nn1.predict.test <-  neuralnet::compute(NN_1_5, test.dummy.scale[,-34])
predicted.class=apply(nn1.predict.test$net.result,1,which.max)-1

confusionMatrix(as.factor(predicted.class), test.dummy.scale$Output, positive = "1")
cm.nn1.test=confusionMatrix(as.factor(predicted.class), test.dummy.scale$Output, positive = "1")
fourfoldplot(cm.nn1.test$table)
```

##### 5 lalyers 5 nodes

```{r}
set.seed(1)

names(train.dummy.scale)[names(train.dummy.scale) == "Occupation.Self Employeed"] <- "Occupation.SelfEmployeed"
names(train.dummy.scale)[names(train.dummy.scale) == "Educational.Qualifications.Post Graduate"] <- "Educational.Qualifications.PostGraduate"

NN_5_5 <- neuralnet(Output ~. , train.dummy.scale, linear.output = FALSE, hidden = c(5,5,5,5,5))

plot(NN_5_5)
```

```{r}
nn1.predict.valid <-  neuralnet::compute(NN_5_5, valid.dummy.scale[,-34])
predicted.class=apply(nn1.predict.valid$net.result,1,which.max)-1

cm.nn2.valid=confusionMatrix(as.factor(predicted.class), valid.dummy.scale$Output, positive = "1")
cm.nn2.valid
fourfoldplot(confusionMatrix(as.factor(predicted.class), valid.dummy.scale$Output, positive = "1")$table)
```

```{r}
nn1.predict.test <-  neuralnet::compute(NN_5_5, test.dummy.scale[,-34])
predicted.class=apply(nn1.predict.test$net.result,1,which.max)-1

cm.nn2.test=confusionMatrix(as.factor(predicted.class), test.dummy.scale$Output, positive = "1")
cm.nn2.test
fourfoldplot(confusionMatrix(as.factor(predicted.class), test.dummy.scale$Output, positive = "1")$table)
```

#### Classification Tree

##### Full-grown tree
```{r message=FALSE, warning=FALSE}
set.seed(1)
full_CT = rpart(Output ~ ., data = train, method = "class", cp=0, minbucket=1, minsplit = 1, xval =5)
length(full_CT$frame$var[full_CT$frame$var == "<leaf>"])
```

```{r message=FALSE, warning=FALSE}
rpart.plot(full_CT, type = 1, extra = 1, under = TRUE, split.font = 1, varlen = -10)
```

```{r}
row_minxerr=which.min(full_CT$cptable[,4])
cp_minxerr=full_CT$cptable[row_minxerr,1]
cp_minxerr
```

```{r}
minxerr=full_CT$cptable[row_minxerr,4]
xstd_minxerr=full_CT$cptable[row_minxerr,5]
cp_best_pruned_CT=minxerr+xstd_minxerr
cp_best_pruned_CT
```
```{r}
printcp(full_CT)[,4]
```
```{r}
cp_xerr=full_CT$cptable[5,1]
cp_xerr
```
```{r}
plotcp(full_CT) + 
abline(v = row_minxerr, lty = "dashed")+
abline(v = 5, lty = "dotted")
```

Let’s prune 2 classification trees: first one with CP of 1 split(which has the lowest cross-validation error) and second with CP of 7 splits(best-pruned classification tree)

##### Pruned classification tree
```{r}
set.seed(1)
pruned_CT <- prune(full_CT, cp = cp_minxerr)
length(pruned_CT$frame$var[pruned_CT$frame$var == "<leaf>"])
```
```{r}
rpart.plot(pruned_CT, type = 1, extra = 1, under = TRUE, split.font = 1, varlen = -10)
```

```{r}
pred_valid_pruned_CT= predict(pruned_CT, valid, type="class")

valid$Output=as.factor(valid$Output)
CT_cm_valid=confusionMatrix(pred_valid_pruned_CT, valid$Output , positive = "1")
CT_cm_valid
fourfoldplot(confusionMatrix(pred_valid_pruned_CT, valid$Output , positive = "1")$table)
```


```{r}
pred_test_pruned_CT= predict(pruned_CT, test, type="class")

test$Output=as.factor(test$Output)
CT_cm_test=confusionMatrix(pred_test_pruned_CT, test$Output , positive = "1")
CT_cm_test

fourfoldplot(confusionMatrix(pred_test_pruned_CT, test$Output , positive = "1")$table)
```


##### Best pruned classification tree

```{r}
best_pruned_CT <- prune(full_CT,cp = cp_xerr)
length(best_pruned_CT$frame$var[best_pruned_CT$frame$var == "<leaf>"])
```

```{r}
rpart.plot(best_pruned_CT, type = 1, extra = 1, under = TRUE, split.font = 1, varlen = -10)
```

```{r}
pred_valid_best_pruned_CT= predict(best_pruned_CT, valid, type="class")

valid$Output=as.factor(valid$Output)
CT_cm_valid=confusionMatrix(pred_valid_best_pruned_CT, valid$Output , positive = "1")
CT_cm_valid

fourfoldplot(confusionMatrix(pred_valid_best_pruned_CT, valid$Output , positive = "1")$table)
```


```{r}
pred_test_best_pruned_CT= predict(best_pruned_CT, test, type="class")

test$Output=as.factor(test$Output)
CT_cm_test=confusionMatrix(pred_test_best_pruned_CT, test$Output , positive = "1")
CT_cm_test

fourfoldplot(confusionMatrix(pred_test_best_pruned_CT, test$Output , positive = "1")$table)
```

#### Boosted

```{r}
set.seed(1)
boost <- boosting(Output ~ ., data = train)
```

```{r}
pred_boost_valid <- predict(boost, valid)
boost_valid.cm = confusionMatrix(as.factor(pred_boost_valid$class), valid$Output, positive = "1")

boost_valid.cm
fourfoldplot(boost_valid.cm$table)
```

```{r}
pred_boost_test <- predict(boost, test)
boost_test.cm = confusionMatrix(as.factor(pred_boost_test$class), (test$Output),positive = "1")

boost_test.cm
fourfoldplot(boost_test.cm$table)
```

#### Bagged

```{r}
set.seed(1)
bagt <- bagging(Output ~ ., data = train)
```

```{r}
pred <- predict(bagt, valid)
bag_valid.cm = confusionMatrix(as.factor(pred$class), valid$Output,positive = "1")

bag_valid.cm
fourfoldplot(bag_valid.cm$table)
```

```{r}
pred <- predict(bagt, test)
bag_test.cm = confusionMatrix(as.factor(pred$class), test$Output,positive = "1")

bag_test.cm
fourfoldplot(bag_test.cm$table)
```

#### Random

```{r}
set.seed(1)
rf <- randomForest(Output ~ ., data = train, mtry=4, importance = T)
```


```{r}
pred <- predict(rf, valid)

rf_valid.cm = confusionMatrix(as.factor(pred), valid$Output,positive = "1")

rf_valid.cm
fourfoldplot(rf_valid.cm$table)
```

```{r}
pred <- predict(rf, test)

rf_test.cm = confusionMatrix(as.factor(pred), test$Output, positive = "1")

rf_test.cm
fourfoldplot(rf_test.cm$table)
```

#### Comparison of the methods

```{r}
F1 <- data.frame("model" = c("naive bayes","logistic regression","discriminant analysis","k-NN","neural nets", "classification tree","boosted", "bagged", "random"),
                                
"valid"=c(nb.valid.balanced.acc, lr.valid.balanced.acc, cm.da.valid$byClass["F1"], confusionMatrix(knn14, valid.st[,34], positive = "1")$byClass["F1"] , cm.nn2.valid$byClass["F1"], CT_cm_valid$byClass["F1"], boost_valid.cm$byClass["F1"], bag_valid.cm$byClass["F1"], rf_valid.cm$byClass["F1"]),

"test"=c(nb.test.balanced.acc, lr.test.balanced.acc, cm.da.test$byClass["F1"], confusionMatrix(knn14.test, test.st[,34], positive = "1")$byClass["F1"], cm.nn2.test$byClass["F1"], CT_cm_test$byClass["F1"], boost_test.cm$byClass["F1"], bag_test.cm$byClass["F1"], rf_test.cm$byClass["F1"]))
F1
```

```{r}
balanced_accuracy <- data.frame("model" = c("naive bayes","logistic regression","discriminant analysis","k-NN","neural nets", "classification tree","boosted", "bagged", "random"),
                                
"valid"=c(nb.valid.balanced.acc, lr.valid.balanced.acc, cm.da.valid$byClass["Balanced Accuracy"], confusionMatrix(knn14, valid.st[,34], positive = "1")$byClass["Balanced Accuracy"] , cm.nn2.valid$byClass["Balanced Accuracy"], CT_cm_valid$byClass["Balanced Accuracy"], boost_valid.cm$byClass["Balanced Accuracy"], bag_valid.cm$byClass["Balanced Accuracy"], rf_valid.cm$byClass["Balanced Accuracy"]),

"test"=c(nb.test.balanced.acc, lr.test.balanced.acc, cm.da.test$byClass["Balanced Accuracy"], confusionMatrix(knn14.test, test.st[,34], positive = "1")$byClass["Balanced Accuracy"], cm.nn2.test$byClass["Balanced Accuracy"], CT_cm_test$byClass["Balanced Accuracy"], boost_test.cm$byClass["Balanced Accuracy"], bag_test.cm$byClass["Balanced Accuracy"], rf_test.cm$byClass["Balanced Accuracy"]))
balanced_accuracy
```

## Subset of 20 predictors

```{r message=FALSE, warning=FALSE}
df2 = df1[,c(8,	9,	12,	10,	21,	11,	1	,30	,17,	14,	13,	39,	4,27, 3,23,40,20, 15, 5, 45)]

str(df2)
```

#### Dummies

```{r message=FALSE, warning=FALSE}
df2$Occupation=as.factor(df2$Occupation)
df2$Marital.Status =as.factor(df2$Marital.Status)

dummies=dummyVars(~., data=df2[,-21])
df.dummy=as.data.frame(predict(dummies, newdata=df2))

df.dummy=df.dummy[,-c(14,19)]
str(df.dummy)
```

```{r message=FALSE, warning=FALSE}
df.dummy$Output <- as.factor(df2$Output)
str(df.dummy)
```

#### Partitioning

```{r message=FALSE, warning=FALSE}
set.seed(1)

train_rows <- createDataPartition(df2$Output, p = .5, list = FALSE)
train <- df2[train_rows,]
valid_test <- df2[-train_rows,]
set.seed(1)
valid_rows <- createDataPartition(valid_test$Output, p = .6, list = FALSE)
valid <- valid_test[valid_rows,]
test <- valid_test[-valid_rows,]
```

```{r message=FALSE, warning=FALSE}
set.seed(1)
train_rows1 <- createDataPartition(df.dummy$Output, p = .5, list = FALSE)
train.dummy <- df.dummy[train_rows1,]
valid_test.dummy <- df.dummy[-train_rows1,]
set.seed(1)
valid_rows1 <- createDataPartition(valid_test.dummy$Output, p = .6, list = FALSE)
valid.dummy <- valid_test.dummy[valid_rows1,]
test.dummy <- valid_test.dummy[-valid_rows1,]
```


```{r message=FALSE, warning=FALSE}
print(table(train$Output) / table(df2$Output)) #Training set partition
print(table(valid$Output) / table(df2$Output)) #Validation set partition
print(table(test$Output) / table(df2$Output)) #Test set partition
```

#### Naive Bayes

```{r message=FALSE, warning=FALSE}
naivebayes <- naiveBayes(Output ~., data=train)
naivebayes
```

```{r message=FALSE, warning=FALSE}
pred_valid.nb <- predict(naivebayes, newdata = valid)
pred_test.nb <- predict(naivebayes, newdata = test)
nb.valid.balanced.acc=confusionMatrix(pred_valid.nb, valid$Output, positive = "1")$byClass["Balanced Accuracy"]
nb.test.balanced.acc=confusionMatrix(pred_test.nb, test$Output,positive = "1")$byClass["Balanced Accuracy"]
confusionMatrix(pred_valid.nb, valid$Output, positive = "1")
fourfoldplot(confusionMatrix(pred_valid.nb, valid$Output, positive = "1")$table)
```

```{r message=FALSE, warning=FALSE}
confusionMatrix(pred_test.nb, test$Output, positive = "1")
fourfoldplot(confusionMatrix(pred_test.nb, test$Output, positive = "1")$table)
```

#### Logistic Regression

```{r}
log.reg <- glm(Output ~ ., data = train, family = "binomial")
options(scipen=999)
summary(log.reg)
```

```{r}
pred_valid.log <- predict(log.reg, valid, type = "response")
pred_test.log <- predict(log.reg, test, type = "response")

lr.valid.balanced.acc=confusionMatrix(as.factor(ifelse(pred_valid.log > 0.5, 1, 0)), valid$Output, positive = "1")$byClass["Balanced Accuracy"]
lr.test.balanced.acc=confusionMatrix(as.factor(ifelse(pred_test.log > 0.5, 1, 0)), test$Output, positive = "1")$byClass["Balanced Accuracy"]
confusionMatrix(as.factor(ifelse(pred_valid.log > 0.5, 1, 0)), valid$Output, positive = "1")
fourfoldplot(confusionMatrix(as.factor(ifelse(pred_valid.log > 0.5, 1, 0)), valid$Output, positive = "1")$table)
```

```{r}
confusionMatrix(as.factor(ifelse(pred_test.log > 0.5, 1, 0)), test$Output, positive = "1")
fourfoldplot(confusionMatrix(as.factor(ifelse(pred_test.log > 0.5, 1, 0)), test$Output, positive = "1")$table)
```

#### Discriminant analysis

```{r}
model1 <- lda(Output~., data = train)
model1
```

```{r}
pred.valid=predict(model1,valid[,-31])

cm.da.valid=confusionMatrix(as.factor(pred.valid$class),as.factor(valid$Output) ,positive = "1")
cm.da.valid

fourfoldplot(cm.da.valid$table)
```

```{r}
da.pred.test=predict(model1,test[,-31])

cm.da.test=confusionMatrix(as.factor(da.pred.test$class),as.factor(test$Output) ,positive = "1")
cm.da.test

fourfoldplot(cm.da.test$table)
```

#### Classification Tree

##### Full-grown tree
```{r message=FALSE, warning=FALSE}
set.seed(1)
full_CT = rpart(Output ~ ., data = train, method = "class", cp=0, minbucket=1, minsplit = 1, xval =5)
length(full_CT$frame$var[full_CT$frame$var == "<leaf>"])
```

```{r message=FALSE, warning=FALSE}
rpart.plot(full_CT, type = 1, extra = 1, under = TRUE, split.font = 1, varlen = -10)
```

```{r}
row_minxerr=which.min(full_CT$cptable[,4])
cp_minxerr=full_CT$cptable[row_minxerr,1]
cp_minxerr
```

```{r}
minxerr=full_CT$cptable[row_minxerr,4]
xstd_minxerr=full_CT$cptable[row_minxerr,5]
cp_best_pruned_CT=minxerr+xstd_minxerr
cp_best_pruned_CT
```
```{r}
printcp(full_CT)[,4]
```
```{r}
cp_xerr=full_CT$cptable[5,1]
cp_xerr
```
```{r}
plotcp(full_CT) + 
abline(v = row_minxerr, lty = "dashed")+
abline(v = 5, lty = "dotted")
```

Let’s prune 2 classification trees: first one with CP of 1 split(which has the lowest cross-validation error) and second with CP of 7 splits(best-pruned classification tree)

##### Pruned classification tree
```{r}
set.seed(1)
pruned_CT <- prune(full_CT, cp = cp_minxerr)
length(pruned_CT$frame$var[pruned_CT$frame$var == "<leaf>"])
```
```{r}
rpart.plot(pruned_CT, type = 1, extra = 1, under = TRUE, split.font = 1, varlen = -10)
```

```{r}
pred_valid_pruned_CT= predict(pruned_CT, valid, type="class")

valid$Output=as.factor(valid$Output)
CT_cm_valid=confusionMatrix(pred_valid_pruned_CT, valid$Output , positive = "1")
CT_cm_valid
fourfoldplot(confusionMatrix(pred_valid_pruned_CT, valid$Output , positive = "1")$table)
```


```{r}
pred_test_pruned_CT= predict(pruned_CT, test, type="class")

test$Output=as.factor(test$Output)
CT_cm_test=confusionMatrix(pred_test_pruned_CT, test$Output , positive = "1")
CT_cm_test

fourfoldplot(confusionMatrix(pred_test_pruned_CT, test$Output , positive = "1")$table)
```


##### Best pruned classification tree

```{r}
best_pruned_CT <- prune(full_CT,cp = cp_xerr)
length(best_pruned_CT$frame$var[best_pruned_CT$frame$var == "<leaf>"])
```

```{r}
rpart.plot(best_pruned_CT, type = 1, extra = 1, under = TRUE, split.font = 1, varlen = -10)
```

```{r}
pred_valid_best_pruned_CT= predict(best_pruned_CT, valid, type="class")

valid$Output=as.factor(valid$Output)
CT_cm_valid=confusionMatrix(pred_valid_best_pruned_CT, valid$Output , positive = "1")
CT_cm_valid

fourfoldplot(confusionMatrix(pred_valid_best_pruned_CT, valid$Output , positive = "1")$table)
```


```{r}
pred_test_best_pruned_CT= predict(best_pruned_CT, test, type="class")

test$Output=as.factor(test$Output)
CT_cm_test=confusionMatrix(pred_test_best_pruned_CT, test$Output , positive = "1")
CT_cm_test

fourfoldplot(confusionMatrix(pred_test_best_pruned_CT, test$Output , positive = "1")$table)
```

#### Boosted

```{r}
set.seed(1)
boost <- boosting(Output ~ ., data = train)
```

```{r}
pred_boost_valid <- predict(boost, valid)
boost_valid.cm = confusionMatrix(as.factor(pred_boost_valid$class), valid$Output, positive = "1")

boost_valid.cm
fourfoldplot(boost_valid.cm$table)
```

```{r}
pred_boost_test <- predict(boost, test)
boost_test.cm = confusionMatrix(as.factor(pred_boost_test$class), (test$Output),positive = "1")

boost_test.cm
fourfoldplot(boost_test.cm$table)
```

#### Bagged

```{r}
set.seed(1)
bagt <- bagging(Output ~ ., data = train)
```

```{r}
pred <- predict(bagt, valid)
bag_valid.cm = confusionMatrix(as.factor(pred$class), valid$Output,positive = "1")

bag_valid.cm
fourfoldplot(bag_valid.cm$table)
```

```{r}
pred <- predict(bagt, test)
bag_test.cm = confusionMatrix(as.factor(pred$class), test$Output,positive = "1")

bag_test.cm
fourfoldplot(bag_test.cm$table)
```

#### Random

```{r}
set.seed(1)
rf <- randomForest(Output ~ ., data = train, mtry=4, importance = T)
```


```{r}
pred <- predict(rf, valid)

rf_valid.cm = confusionMatrix(as.factor(pred), valid$Output,positive = "1")

rf_valid.cm
fourfoldplot(rf_valid.cm$table)
```

```{r}
pred <- predict(rf, test)

rf_test.cm = confusionMatrix(as.factor(pred), test$Output, positive = "1")

rf_test.cm
fourfoldplot(rf_test.cm$table)
```

#### Comparison of the methods

```{r}
F1 <- data.frame("model" = c("naive bayes","logistic regression","discriminant analysis","classification tree","boosted", "bagged", "random"),
                                
"valid"=c(nb.valid.balanced.acc, lr.valid.balanced.acc, cm.da.valid$byClass["F1"], CT_cm_valid$byClass["F1"], boost_valid.cm$byClass["F1"], bag_valid.cm$byClass["F1"], rf_valid.cm$byClass["F1"]),

"test"=c(nb.test.balanced.acc, lr.test.balanced.acc, cm.da.test$byClass["F1"],CT_cm_test$byClass["F1"], boost_test.cm$byClass["F1"], bag_test.cm$byClass["F1"], rf_test.cm$byClass["F1"]))
F1
```

```{r}
balanced_accuracy <- data.frame("model" = c("naive bayes","logistic regression","discriminant analysis","classification tree","boosted", "bagged", "random"),
                                
"valid"=c(nb.valid.balanced.acc, lr.valid.balanced.acc, cm.da.valid$byClass["Balanced Accuracy"], CT_cm_valid$byClass["Balanced Accuracy"], boost_valid.cm$byClass["Balanced Accuracy"], bag_valid.cm$byClass["Balanced Accuracy"], rf_valid.cm$byClass["Balanced Accuracy"]),

"test"=c(nb.test.balanced.acc, lr.test.balanced.acc, cm.da.test$byClass["Balanced Accuracy"],CT_cm_test$byClass["Balanced Accuracy"], boost_test.cm$byClass["Balanced Accuracy"], bag_test.cm$byClass["Balanced Accuracy"], rf_test.cm$byClass["Balanced Accuracy"]))
balanced_accuracy
```


## Subset of 15 predictors

```{r message=FALSE, warning=FALSE}
df2 = df1[,c(8,	9,	12,	10,	21,	11,	1	,30	,17,	14,	13,	39,	4,27, 3,45)]

str(df2)
```

#### Dummies

```{r message=FALSE, warning=FALSE}
df2$Occupation=as.factor(df2$Occupation)
df2$Marital.Status =as.factor(df2$Marital.Status)

dummies=dummyVars(~., data=df2[,-16])
df.dummy=as.data.frame(predict(dummies, newdata=df2))

df.dummy=df.dummy[,-c(14,19)]
str(df.dummy)
```

```{r message=FALSE, warning=FALSE}
df.dummy$Output <- as.factor(df2$Output)
str(df.dummy)
```

#### Partitioning

```{r message=FALSE, warning=FALSE}
set.seed(1)

train_rows <- createDataPartition(df2$Output, p = .5, list = FALSE)
train <- df2[train_rows,]
valid_test <- df2[-train_rows,]
set.seed(1)
valid_rows <- createDataPartition(valid_test$Output, p = .6, list = FALSE)
valid <- valid_test[valid_rows,]
test <- valid_test[-valid_rows,]
```

```{r message=FALSE, warning=FALSE}
set.seed(1)
train_rows1 <- createDataPartition(df.dummy$Output, p = .5, list = FALSE)
train.dummy <- df.dummy[train_rows1,]
valid_test.dummy <- df.dummy[-train_rows1,]
set.seed(1)
valid_rows1 <- createDataPartition(valid_test.dummy$Output, p = .6, list = FALSE)
valid.dummy <- valid_test.dummy[valid_rows1,]
test.dummy <- valid_test.dummy[-valid_rows1,]
```


```{r message=FALSE, warning=FALSE}
print(table(train$Output) / table(df2$Output)) #Training set partition
print(table(valid$Output) / table(df2$Output)) #Validation set partition
print(table(test$Output) / table(df2$Output)) #Test set partition
```

#### Naive Bayes

```{r message=FALSE, warning=FALSE}
naivebayes <- naiveBayes(Output ~., data=train)
naivebayes
```

```{r message=FALSE, warning=FALSE}
pred_valid.nb <- predict(naivebayes, newdata = valid)
pred_test.nb <- predict(naivebayes, newdata = test)
nb.valid.balanced.acc=confusionMatrix(pred_valid.nb, valid$Output, positive = "1")$byClass["Balanced Accuracy"]
nb.test.balanced.acc=confusionMatrix(pred_test.nb, test$Output,positive = "1")$byClass["Balanced Accuracy"]
confusionMatrix(pred_valid.nb, valid$Output, positive = "1")
fourfoldplot(confusionMatrix(pred_valid.nb, valid$Output, positive = "1")$table)
```

```{r message=FALSE, warning=FALSE}
confusionMatrix(pred_test.nb, test$Output, positive = "1")
fourfoldplot(confusionMatrix(pred_test.nb, test$Output, positive = "1")$table)
```

#### Logistic Regression

```{r}
log.reg <- glm(Output ~ ., data = train, family = "binomial")
options(scipen=999)
summary(log.reg)
```

```{r}
pred_valid.log <- predict(log.reg, valid, type = "response")
pred_test.log <- predict(log.reg, test, type = "response")

lr.valid.balanced.acc=confusionMatrix(as.factor(ifelse(pred_valid.log > 0.5, 1, 0)), valid$Output, positive = "1")$byClass["Balanced Accuracy"]
lr.test.balanced.acc=confusionMatrix(as.factor(ifelse(pred_test.log > 0.5, 1, 0)), test$Output, positive = "1")$byClass["Balanced Accuracy"]
confusionMatrix(as.factor(ifelse(pred_valid.log > 0.5, 1, 0)), valid$Output, positive = "1")
fourfoldplot(confusionMatrix(as.factor(ifelse(pred_valid.log > 0.5, 1, 0)), valid$Output, positive = "1")$table)
```

```{r}
confusionMatrix(as.factor(ifelse(pred_test.log > 0.5, 1, 0)), test$Output, positive = "1")
fourfoldplot(confusionMatrix(as.factor(ifelse(pred_test.log > 0.5, 1, 0)), test$Output, positive = "1")$table)
```

#### Discriminant analysis

```{r}
model1 <- lda(Output~., data = train)
model1
```

```{r}
pred.valid=predict(model1,valid[,-31])

cm.da.valid=confusionMatrix(as.factor(pred.valid$class),as.factor(valid$Output) ,positive = "1")
cm.da.valid

fourfoldplot(cm.da.valid$table)
```

```{r}
da.pred.test=predict(model1,test[,-31])

cm.da.test=confusionMatrix(as.factor(da.pred.test$class),as.factor(test$Output) ,positive = "1")
cm.da.test

fourfoldplot(cm.da.test$table)
```

#### Classification Tree

##### Full-grown tree
```{r message=FALSE, warning=FALSE}
set.seed(1)
full_CT = rpart(Output ~ ., data = train, method = "class", cp=0, minbucket=1, minsplit = 1, xval =5)
length(full_CT$frame$var[full_CT$frame$var == "<leaf>"])
```

```{r message=FALSE, warning=FALSE}
rpart.plot(full_CT, type = 1, extra = 1, under = TRUE, split.font = 1, varlen = -10)
```

```{r}
row_minxerr=which.min(full_CT$cptable[,4])
cp_minxerr=full_CT$cptable[row_minxerr,1]
cp_minxerr
```

```{r}
minxerr=full_CT$cptable[row_minxerr,4]
xstd_minxerr=full_CT$cptable[row_minxerr,5]
cp_best_pruned_CT=minxerr+xstd_minxerr
cp_best_pruned_CT
```
```{r}
printcp(full_CT)[,4]
```
```{r}
cp_xerr=full_CT$cptable[5,1]
cp_xerr
```
```{r}
plotcp(full_CT) + 
abline(v = row_minxerr, lty = "dashed")+
abline(v = 5, lty = "dotted")
```

Let’s prune 2 classification trees: first one with CP of 1 split(which has the lowest cross-validation error) and second with CP of 7 splits(best-pruned classification tree)

##### Pruned classification tree
```{r}
set.seed(1)
pruned_CT <- prune(full_CT, cp = cp_minxerr)
length(pruned_CT$frame$var[pruned_CT$frame$var == "<leaf>"])
```
```{r}
rpart.plot(pruned_CT, type = 1, extra = 1, under = TRUE, split.font = 1, varlen = -10)
```

```{r}
pred_valid_pruned_CT= predict(pruned_CT, valid, type="class")

valid$Output=as.factor(valid$Output)
CT_cm_valid=confusionMatrix(pred_valid_pruned_CT, valid$Output , positive = "1")
CT_cm_valid
fourfoldplot(confusionMatrix(pred_valid_pruned_CT, valid$Output , positive = "1")$table)
```


```{r}
pred_test_pruned_CT= predict(pruned_CT, test, type="class")

test$Output=as.factor(test$Output)
CT_cm_test=confusionMatrix(pred_test_pruned_CT, test$Output , positive = "1")
CT_cm_test

fourfoldplot(confusionMatrix(pred_test_pruned_CT, test$Output , positive = "1")$table)
```


##### Best pruned classification tree

```{r}
best_pruned_CT <- prune(full_CT,cp = cp_xerr)
length(best_pruned_CT$frame$var[best_pruned_CT$frame$var == "<leaf>"])
```

```{r}
rpart.plot(best_pruned_CT, type = 1, extra = 1, under = TRUE, split.font = 1, varlen = -10)
```

```{r}
pred_valid_best_pruned_CT= predict(best_pruned_CT, valid, type="class")

valid$Output=as.factor(valid$Output)
CT_cm_valid=confusionMatrix(pred_valid_best_pruned_CT, valid$Output , positive = "1")
CT_cm_valid

fourfoldplot(confusionMatrix(pred_valid_best_pruned_CT, valid$Output , positive = "1")$table)
```


```{r}
pred_test_best_pruned_CT= predict(best_pruned_CT, test, type="class")

test$Output=as.factor(test$Output)
CT_cm_test=confusionMatrix(pred_test_best_pruned_CT, test$Output , positive = "1")
CT_cm_test

fourfoldplot(confusionMatrix(pred_test_best_pruned_CT, test$Output , positive = "1")$table)
```

#### Boosted

```{r}
set.seed(1)
boost <- boosting(Output ~ ., data = train)
```

```{r}
pred_boost_valid <- predict(boost, valid)
boost_valid.cm = confusionMatrix(as.factor(pred_boost_valid$class), valid$Output, positive = "1")

boost_valid.cm
fourfoldplot(boost_valid.cm$table)
```

```{r}
pred_boost_test <- predict(boost, test)
boost_test.cm = confusionMatrix(as.factor(pred_boost_test$class), (test$Output),positive = "1")

boost_test.cm
fourfoldplot(boost_test.cm$table)
```

#### Bagged

```{r}
set.seed(1)
bagt <- bagging(Output ~ ., data = train)
```

```{r}
pred <- predict(bagt, valid)
bag_valid.cm = confusionMatrix(as.factor(pred$class), valid$Output,positive = "1")

bag_valid.cm
fourfoldplot(bag_valid.cm$table)
```

```{r}
pred <- predict(bagt, test)
bag_test.cm = confusionMatrix(as.factor(pred$class), test$Output,positive = "1")

bag_test.cm
fourfoldplot(bag_test.cm$table)
```

#### Random

```{r}
set.seed(1)
rf <- randomForest(Output ~ ., data = train, mtry=4, importance = T)
```


```{r}
pred <- predict(rf, valid)

rf_valid.cm = confusionMatrix(as.factor(pred), valid$Output,positive = "1")

rf_valid.cm
fourfoldplot(rf_valid.cm$table)
```

```{r}
pred <- predict(rf, test)

rf_test.cm = confusionMatrix(as.factor(pred), test$Output, positive = "1")

rf_test.cm
fourfoldplot(rf_test.cm$table)
```

#### Comparison of the methods

```{r}
F1 <- data.frame("model" = c("naive bayes","logistic regression","discriminant analysis","classification tree","boosted", "bagged", "random"),
                                
"valid"=c(nb.valid.balanced.acc, lr.valid.balanced.acc, cm.da.valid$byClass["F1"], CT_cm_valid$byClass["F1"], boost_valid.cm$byClass["F1"], bag_valid.cm$byClass["F1"], rf_valid.cm$byClass["F1"]),

"test"=c(nb.test.balanced.acc, lr.test.balanced.acc, cm.da.test$byClass["F1"],CT_cm_test$byClass["F1"], boost_test.cm$byClass["F1"], bag_test.cm$byClass["F1"], rf_test.cm$byClass["F1"]))
F1
```

```{r}
balanced_accuracy <- data.frame("model" = c("naive bayes","logistic regression","discriminant analysis","classification tree","boosted", "bagged", "random"),
                                
"valid"=c(nb.valid.balanced.acc, lr.valid.balanced.acc, cm.da.valid$byClass["Balanced Accuracy"], CT_cm_valid$byClass["Balanced Accuracy"], boost_valid.cm$byClass["Balanced Accuracy"], bag_valid.cm$byClass["Balanced Accuracy"], rf_valid.cm$byClass["Balanced Accuracy"]),

"test"=c(nb.test.balanced.acc, lr.test.balanced.acc, cm.da.test$byClass["Balanced Accuracy"],CT_cm_test$byClass["Balanced Accuracy"], boost_test.cm$byClass["Balanced Accuracy"], bag_test.cm$byClass["Balanced Accuracy"], rf_test.cm$byClass["Balanced Accuracy"]))
balanced_accuracy
```


## Subset of 13 predictors

```{r message=FALSE, warning=FALSE}
df2 = df1[,c(8,	9,	12,	10,	21,	11,	1	,30	,17,	14,	13,	39,	4,45)]

str(df2)
```

#### Dummies

```{r message=FALSE, warning=FALSE}
df2$Occupation=as.factor(df2$Occupation)

dummies=dummyVars(~., data=df2[,-14])
df.dummy=as.data.frame(predict(dummies, newdata=df2))

df.dummy=df.dummy[,-c(14)]
str(df.dummy)
```

```{r message=FALSE, warning=FALSE}
df.dummy$Output <- as.factor(df2$Output)
str(df.dummy)
```

#### Partitioning

```{r message=FALSE, warning=FALSE}
set.seed(1)

train_rows <- createDataPartition(df2$Output, p = .5, list = FALSE)
train <- df2[train_rows,]
valid_test <- df2[-train_rows,]
set.seed(1)
valid_rows <- createDataPartition(valid_test$Output, p = .6, list = FALSE)
valid <- valid_test[valid_rows,]
test <- valid_test[-valid_rows,]
```

```{r message=FALSE, warning=FALSE}
set.seed(1)
train_rows1 <- createDataPartition(df.dummy$Output, p = .5, list = FALSE)
train.dummy <- df.dummy[train_rows1,]
valid_test.dummy <- df.dummy[-train_rows1,]
set.seed(1)
valid_rows1 <- createDataPartition(valid_test.dummy$Output, p = .6, list = FALSE)
valid.dummy <- valid_test.dummy[valid_rows1,]
test.dummy <- valid_test.dummy[-valid_rows1,]
```


```{r message=FALSE, warning=FALSE}
print(table(train$Output) / table(df2$Output)) #Training set partition
print(table(valid$Output) / table(df2$Output)) #Validation set partition
print(table(test$Output) / table(df2$Output)) #Test set partition
```

#### Naive Bayes

```{r message=FALSE, warning=FALSE}
naivebayes <- naiveBayes(Output ~., data=train)
naivebayes
```

```{r message=FALSE, warning=FALSE}
pred_valid.nb <- predict(naivebayes, newdata = valid)
pred_test.nb <- predict(naivebayes, newdata = test)
nb.valid.balanced.acc=confusionMatrix(pred_valid.nb, valid$Output, positive = "1")$byClass["Balanced Accuracy"]
nb.test.balanced.acc=confusionMatrix(pred_test.nb, test$Output,positive = "1")$byClass["Balanced Accuracy"]
confusionMatrix(pred_valid.nb, valid$Output, positive = "1")
fourfoldplot(confusionMatrix(pred_valid.nb, valid$Output, positive = "1")$table)
```

```{r message=FALSE, warning=FALSE}
confusionMatrix(pred_test.nb, test$Output, positive = "1")
fourfoldplot(confusionMatrix(pred_test.nb, test$Output, positive = "1")$table)
```

#### Logistic Regression

```{r}
log.reg <- glm(Output ~ ., data = train, family = "binomial")
options(scipen=999)
summary(log.reg)
```

```{r}
pred_valid.log <- predict(log.reg, valid, type = "response")
pred_test.log <- predict(log.reg, test, type = "response")

lr.valid.balanced.acc=confusionMatrix(as.factor(ifelse(pred_valid.log > 0.5, 1, 0)), valid$Output, positive = "1")$byClass["Balanced Accuracy"]
lr.test.balanced.acc=confusionMatrix(as.factor(ifelse(pred_test.log > 0.5, 1, 0)), test$Output, positive = "1")$byClass["Balanced Accuracy"]
confusionMatrix(as.factor(ifelse(pred_valid.log > 0.5, 1, 0)), valid$Output, positive = "1")
fourfoldplot(confusionMatrix(as.factor(ifelse(pred_valid.log > 0.5, 1, 0)), valid$Output, positive = "1")$table)
```

```{r}
confusionMatrix(as.factor(ifelse(pred_test.log > 0.5, 1, 0)), test$Output, positive = "1")
fourfoldplot(confusionMatrix(as.factor(ifelse(pred_test.log > 0.5, 1, 0)), test$Output, positive = "1")$table)
```

#### Discriminant analysis

```{r}
model1 <- lda(Output~., data = train)
model1
```

```{r}
pred.valid=predict(model1,valid[,-31])

cm.da.valid=confusionMatrix(as.factor(pred.valid$class),as.factor(valid$Output) ,positive = "1")
cm.da.valid

fourfoldplot(cm.da.valid$table)
```

```{r}
da.pred.test=predict(model1,test[,-31])

cm.da.test=confusionMatrix(as.factor(da.pred.test$class),as.factor(test$Output) ,positive = "1")
cm.da.test

fourfoldplot(cm.da.test$table)
```

#### KNN

```{r}
train.st <- train.dummy
valid.st <- valid.dummy
test.st <- test.dummy

standard.values = preProcess(train.dummy[,c(1:12)], method=c("center", "scale"))
train.st[,c(1:12)] <- predict(standard.values, train.dummy[,c(1:12)])
valid.st[,c(1:12)] <- predict(standard.values, valid.dummy[,c(1:12)])
test.st[,c(1:12)] <- predict(standard.values, test.dummy[,c(1:12)])

str(train.st)
```

```{r message=FALSE, warning=FALSE}
metrics <- data.frame(k=seq(1, 30, 1), balanced_accuracy = rep(0, 30), F1_score = rep(0, 30))

for(i in 1:30) {
  knn <- knn(train=train.st[,-16], test=valid.st[,-16], cl=train.st[,16], k=i)
  metrics[i, 2] = confusionMatrix(knn, valid.st[,16], positive = "1")$byClass["Balanced Accuracy"]
  metrics[i, 3] = confusionMatrix(knn, valid.st[,16], positive = "1")$byClass["F1"]
}

ggplot(data= metrics)+ 
  geom_line(aes(x=k, y=balanced_accuracy))+
  theme_bw()
ggplot(data= metrics)+ 
  geom_line(aes(x=k, y=F1_score))+
  theme_bw()

which.max(metrics$balanced_accuracy)
which.max(metrics$F1_score)
```

```{r}
knn1 <- knn(train=train.st[,-16], test=valid.st[,-16], cl=train.st[,16], k=1)
knn1.test <- knn(train=train.st[,-16], test=test.st[,-16], cl=train.st[,16], k=1)

confusionMatrix(knn1, valid.st[,16], positive = "1")$byClass["Balanced Accuracy"]
confusionMatrix(knn1.test, test.st[,16], positive = "1")$byClass["Balanced Accuracy"]
confusionMatrix(knn1, valid.st[,16], positive = "1")$byClass["F1"]
confusionMatrix(knn1.test, test.st[,16], positive = "1")$byClass["F1"]
```

#### Neural Nets (4 layers 7 nodes)

```{r message=FALSE, warning=FALSE}
train.dummy.scale=train.dummy
valid.dummy.scale=valid.dummy
test.dummy.scale=test.dummy

vars = c(1:12)
norm.values <- preProcess(train.dummy[, vars], method="range") 

train.dummy.scale[,vars] = predict(norm.values, train.dummy[,vars])
valid.dummy.scale[,vars] = predict(norm.values, valid.dummy[,vars])
test.dummy.scale[,vars] = predict(norm.values, test.dummy[,vars])

scale_back_min_max_score <- function(x_) {
  min_x = min(train.dummy$Output)
  max_x = max(train.dummy$Output)
  x = sapply(x_, function(x__) x__*(max_x - min_x) + min_x)
  return(x)
}
```

```{r message=FALSE, warning=FALSE}
set.seed(1)

names(train.dummy.scale)[names(train.dummy.scale) == "Occupation.Self Employeed"] <- "Occupation.SelfEmployeed"

NN_4_7 <- neuralnet(Output ~. , train.dummy.scale, linear.output = FALSE, hidden = c(7,7,7,7))
plot(NN_4_7)
```

```{r message=FALSE, warning=FALSE}
nn.predict.valid <-  neuralnet::compute(NN_4_7, valid.dummy.scale[,-16])
predicted.class=apply(nn.predict.valid$net.result,1,which.max)-1

cm.nn.valid=confusionMatrix(as.factor(predicted.class), valid.dummy.scale$Output, positive = "1")
cm.nn.valid
fourfoldplot(cm.nn.valid$table)
```

```{r message=FALSE, warning=FALSE}
nn.predict.test <-  neuralnet::compute(NN_4_7, test.dummy.scale[,-16])
predicted.class=apply(nn.predict.test$net.result,1,which.max)-1

cm.nn.test=confusionMatrix(as.factor(predicted.class), test.dummy.scale$Output, positive = "1")
cm.nn.test
fourfoldplot(cm.nn.test$table)
```

#### Classification Tree

##### Full-grown tree
```{r message=FALSE, warning=FALSE}
set.seed(1)
full_CT = rpart(Output ~ ., data = train, method = "class", cp=0, minbucket=1, minsplit = 1, xval =5)
length(full_CT$frame$var[full_CT$frame$var == "<leaf>"])
```

```{r message=FALSE, warning=FALSE}
rpart.plot(full_CT, type = 1, extra = 1, under = TRUE, split.font = 1, varlen = -10)
```

```{r}
row_minxerr=which.min(full_CT$cptable[,4])
cp_minxerr=full_CT$cptable[row_minxerr,1]
cp_minxerr
```

```{r}
minxerr=full_CT$cptable[row_minxerr,4]
xstd_minxerr=full_CT$cptable[row_minxerr,5]
cp_best_pruned_CT=minxerr+xstd_minxerr
cp_best_pruned_CT
```
```{r}
printcp(full_CT)[,4]
```
```{r}
cp_xerr=full_CT$cptable[5,1]
cp_xerr
```
```{r}
plotcp(full_CT) + 
abline(v = row_minxerr, lty = "dashed")+
abline(v = 5, lty = "dotted")
```

Let’s prune 2 classification trees: first one with CP of 1 split(which has the lowest cross-validation error) and second with CP of 7 splits(best-pruned classification tree)

##### Pruned classification tree
```{r}
set.seed(1)
pruned_CT <- prune(full_CT, cp = cp_minxerr)
length(pruned_CT$frame$var[pruned_CT$frame$var == "<leaf>"])
```
```{r}
rpart.plot(pruned_CT, type = 1, extra = 1, under = TRUE, split.font = 1, varlen = -10)
```

```{r}
pred_valid_pruned_CT= predict(pruned_CT, valid, type="class")

valid$Output=as.factor(valid$Output)
CT_cm_valid=confusionMatrix(pred_valid_pruned_CT, valid$Output , positive = "1")
CT_cm_valid
fourfoldplot(confusionMatrix(pred_valid_pruned_CT, valid$Output , positive = "1")$table)
```


```{r}
pred_test_pruned_CT= predict(pruned_CT, test, type="class")

test$Output=as.factor(test$Output)
CT_cm_test=confusionMatrix(pred_test_pruned_CT, test$Output , positive = "1")
CT_cm_test

fourfoldplot(confusionMatrix(pred_test_pruned_CT, test$Output , positive = "1")$table)
```


##### Best pruned classification tree

```{r}
best_pruned_CT <- prune(full_CT,cp = cp_xerr)
length(best_pruned_CT$frame$var[best_pruned_CT$frame$var == "<leaf>"])
```

```{r}
rpart.plot(best_pruned_CT, type = 1, extra = 1, under = TRUE, split.font = 1, varlen = -10)
```

```{r}
pred_valid_best_pruned_CT= predict(best_pruned_CT, valid, type="class")

valid$Output=as.factor(valid$Output)
CT_cm_valid=confusionMatrix(pred_valid_best_pruned_CT, valid$Output , positive = "1")
CT_cm_valid

fourfoldplot(confusionMatrix(pred_valid_best_pruned_CT, valid$Output , positive = "1")$table)
```


```{r}
pred_test_best_pruned_CT= predict(best_pruned_CT, test, type="class")

test$Output=as.factor(test$Output)
CT_cm_test=confusionMatrix(pred_test_best_pruned_CT, test$Output , positive = "1")
CT_cm_test

fourfoldplot(confusionMatrix(pred_test_best_pruned_CT, test$Output , positive = "1")$table)
```

#### Boosted

```{r}
set.seed(1)
boost <- boosting(Output ~ ., data = train)
```

```{r}
pred_boost_valid <- predict(boost, valid)
boost_valid.cm = confusionMatrix(as.factor(pred_boost_valid$class), valid$Output, positive = "1")

boost_valid.cm
fourfoldplot(boost_valid.cm$table)
```

```{r}
pred_boost_test <- predict(boost, test)
boost_test.cm = confusionMatrix(as.factor(pred_boost_test$class), (test$Output),positive = "1")

boost_test.cm
fourfoldplot(boost_test.cm$table)
```

#### Bagged

```{r}
set.seed(1)
bagt <- bagging(Output ~ ., data = train)
```

```{r}
pred <- predict(bagt, valid)
bag_valid.cm = confusionMatrix(as.factor(pred$class), valid$Output,positive = "1")

bag_valid.cm
fourfoldplot(bag_valid.cm$table)
```

```{r}
pred <- predict(bagt, test)
bag_test.cm = confusionMatrix(as.factor(pred$class), test$Output,positive = "1")

bag_test.cm
fourfoldplot(bag_test.cm$table)
```

#### Random

```{r}
set.seed(1)
rf <- randomForest(Output ~ ., data = train, mtry=4, importance = T)
```


```{r}
pred <- predict(rf, valid)

rf_valid.cm = confusionMatrix(as.factor(pred), valid$Output,positive = "1")

rf_valid.cm
fourfoldplot(rf_valid.cm$table)
```

```{r}
pred <- predict(rf, test)

rf_test.cm = confusionMatrix(as.factor(pred), test$Output, positive = "1")

rf_test.cm
fourfoldplot(rf_test.cm$table)
```

#### Comparison of the methods

```{r}
F1 <- data.frame("model" = c("naive bayes","logistic regression","discriminant analysis","k-NN","neural nets", "classification tree","boosted", "bagged", "random"),
                                
"valid"=c(nb.valid.balanced.acc, lr.valid.balanced.acc, cm.da.valid$byClass["F1"], confusionMatrix(knn1, valid.st[,16], positive = "1")$byClass["F1"] , cm.nn.valid$byClass["F1"], CT_cm_valid$byClass["F1"], boost_valid.cm$byClass["F1"], bag_valid.cm$byClass["F1"], rf_valid.cm$byClass["F1"]),

"test"=c(nb.test.balanced.acc, lr.test.balanced.acc, cm.da.test$byClass["F1"], confusionMatrix(knn1.test, test.st[,16], positive = "1")$byClass["F1"], cm.nn.test$byClass["F1"], CT_cm_test$byClass["F1"], boost_test.cm$byClass["F1"], bag_test.cm$byClass["F1"], rf_test.cm$byClass["F1"]))
F1
```

```{r}
balanced_accuracy <- data.frame("model" = c("naive bayes","logistic regression","discriminant analysis","k-NN","neural nets", "classification tree","boosted", "bagged", "random"),
                                
"valid"=c(nb.valid.balanced.acc, lr.valid.balanced.acc, cm.da.valid$byClass["Balanced Accuracy"], confusionMatrix(knn1, valid.st[,16], positive = "1")$byClass["Balanced Accuracy"] , cm.nn.valid$byClass["Balanced Accuracy"], CT_cm_valid$byClass["Balanced Accuracy"], boost_valid.cm$byClass["Balanced Accuracy"], bag_valid.cm$byClass["Balanced Accuracy"], rf_valid.cm$byClass["Balanced Accuracy"]),

"test"=c(nb.test.balanced.acc, lr.test.balanced.acc, cm.da.test$byClass["Balanced Accuracy"], confusionMatrix(knn1.test, test.st[,16], positive = "1")$byClass["Balanced Accuracy"], cm.nn.test$byClass["Balanced Accuracy"], CT_cm_test$byClass["Balanced Accuracy"], boost_test.cm$byClass["Balanced Accuracy"], bag_test.cm$byClass["Balanced Accuracy"], rf_test.cm$byClass["Balanced Accuracy"]))
balanced_accuracy
```

#### Ensemble with neural nets, random forest, boosted

```{r}
#neural nets
#valid
nn.prob.valid <-  neuralnet::compute(NN_4_7, valid.dummy.scale[,-16])$net.result[,2]
nn.class.valid=apply(nn.predict.valid$net.result,1,which.max)-1
nn.class.valid <- as.factor(nn.class.valid)

#test
nn.prob.test <-  neuralnet::compute(NN_4_7, test.dummy.scale[,-16])$net.result[,2]
nn.class.test=apply(nn.predict.test$net.result,1,which.max)-1
nn.class.test <- as.factor(nn.class.test)

#random forest
#valid
rf.class.valid <- predict(rf, valid)
rf.prob.valid <- predict(rf, valid, type="prob")[,2]
#test
rf.class.test <- predict(rf, test)
rf.prob.test <- predict(rf, test, type="prob")[,2]

#boosted
#valid
boost.class.valid <- predict(boost, valid)$class
boost.class.valid <- as.factor(boost.class.valid)
boost.prob.valid <- predict(boost, valid)$prob[,2]
#test
boost.class.test <- predict(boost, test)$class
boost.class.test <- as.factor(boost.class.test)
boost.prob.test <- predict(boost, test)$prob[,2]
```

##### Majority Vote

```{r}
outcome_class_valid <- data.frame(actual=valid$Output, neural_nets=nn.class.valid, random=rf.class.valid, boost=boost.class.valid)

outcome_class_valid$majority_vote <- as.factor(ifelse(outcome_class_valid$neural_nets=='1' & outcome_class_valid$random=='1','1', ifelse(outcome_class_valid$neural_nets=='1' & outcome_class_valid$boost=='1','1', ifelse(outcome_class_valid$random=='1' & outcome_class_valid$boost=='1','1','0'))))

outcome_class_test <- data.frame(actual=test$Output, neural_nets=nn.class.test, random=rf.class.test, boost=boost.class.test)

outcome_class_test$majority_vote <- as.factor(ifelse(outcome_class_test$neural_nets=='1' & outcome_class_test$random=='1','1', ifelse(outcome_class_test$neural_nets=='1' & outcome_class_test$boost=='1','1', ifelse(outcome_class_test$random=='1' & outcome_class_test$boost=='1','1','0'))))
```

```{r}
confusionMatrix(outcome_class_valid$actual, outcome_class_valid$majority_vote, positive="1")$byClass["Balanced Accuracy"]
confusionMatrix(outcome_class_test$actual, outcome_class_test$majority_vote, positive="1")$byClass["Balanced Accuracy"]

confusionMatrix(outcome_class_valid$actual, outcome_class_valid$majority_vote, positive="1")$byClass["F1"]
confusionMatrix(outcome_class_test$actual, outcome_class_test$majority_vote, positive="1")$byClass["F1"]
```

##### Average probabilities

```{r}
outcome_prob_valid <- data.frame(actual=valid$Output, neural_nets=nn.prob.valid, random=rf.prob.valid, boost=boost.prob.valid)

outcome_prob_valid$average <- (outcome_prob_valid$neural_nets + outcome_prob_valid$random + outcome_prob_valid$boost)/3

outcome_prob_valid$average_class <- as.factor(ifelse(outcome_prob_valid$average>0.5, 1, 0))

outcome_prob_test <- data.frame(actual=test$Output, neural_nets=nn.prob.test, random=rf.prob.test, boost=boost.prob.test)

outcome_prob_test$average <- (outcome_prob_test$neural_nets + outcome_prob_test$random + outcome_prob_test$boost)/3

outcome_prob_test$average_class <- as.factor(ifelse(outcome_prob_test$average>0.5, 1, 0))
```

```{r}
confusionMatrix(outcome_prob_valid$actual, outcome_prob_valid$average_class, positive="1")$byClass["Balanced Accuracy"]
confusionMatrix(outcome_prob_test$actual, outcome_prob_test$average_class, positive="1")$byClass["Balanced Accuracy"]

confusionMatrix(outcome_prob_valid$actual, outcome_prob_valid$average_class, positive="1")$byClass["F1"]
confusionMatrix(outcome_prob_test$actual, outcome_prob_test$average_class, positive="1")$byClass["F1"]
```

## {-}

## Comparison of all methods

```{r}
balanced_accuracy <- data.frame("model" = c("naive bayes","logistic regression","discriminant analysis","k-NN","neural nets", "classification tree","boosted", "bagged", "random", "majority vote", "average prob"),
                                
"valid"=c(nb.valid.balanced.acc, lr.valid.balanced.acc, cm.da.valid$byClass["Balanced Accuracy"], confusionMatrix(knn1, valid.st[,16], positive = "1")$byClass["Balanced Accuracy"] , cm.nn.valid$byClass["Balanced Accuracy"], CT_cm_valid$byClass["Balanced Accuracy"], boost_valid.cm$byClass["Balanced Accuracy"], bag_valid.cm$byClass["Balanced Accuracy"], rf_valid.cm$byClass["Balanced Accuracy"], confusionMatrix(outcome_class_valid$actual, outcome_class_valid$majority_vote, positive="1")$byClass["Balanced Accuracy"], confusionMatrix(outcome_prob_valid$actual, outcome_prob_valid$average_class, positive="1")$byClass["Balanced Accuracy"]),

"test"=c(nb.test.balanced.acc, lr.test.balanced.acc, cm.da.test$byClass["Balanced Accuracy"], confusionMatrix(knn1.test, test.st[,16], positive = "1")$byClass["Balanced Accuracy"], cm.nn.test$byClass["Balanced Accuracy"], CT_cm_test$byClass["Balanced Accuracy"], boost_test.cm$byClass["Balanced Accuracy"], bag_test.cm$byClass["Balanced Accuracy"], rf_test.cm$byClass["Balanced Accuracy"], confusionMatrix(outcome_class_test$actual, outcome_class_test$majority_vote, positive="1")$byClass["Balanced Accuracy"], confusionMatrix(outcome_prob_test$actual, outcome_prob_test$average_class, positive="1")$byClass["Balanced Accuracy"]))
balanced_accuracy
```


```{r}
F1 <- data.frame("model" = c("naive bayes","logistic regression","discriminant analysis","k-NN","neural nets", "classification tree","boosted", "bagged", "random", "majority vote", "average prob"),
                                
"valid"=c(nb.valid.balanced.acc, lr.valid.balanced.acc, cm.da.valid$byClass["F1"], confusionMatrix(knn1, valid.st[,16], positive = "1")$byClass["F1"] , cm.nn.valid$byClass["F1"], CT_cm_valid$byClass["F1"], boost_valid.cm$byClass["F1"], bag_valid.cm$byClass["F1"], rf_valid.cm$byClass["F1"], confusionMatrix(outcome_class_valid$actual, outcome_class_valid$majority_vote, positive="1")$byClass["F1"], confusionMatrix(outcome_prob_valid$actual, outcome_prob_valid$average_class, positive="1")$byClass["F1"]),

"test"=c(nb.test.balanced.acc, lr.test.balanced.acc, cm.da.test$byClass["F1"], confusionMatrix(knn1.test, test.st[,16], positive = "1")$byClass["F1"], cm.nn.test$byClass["F1"], CT_cm_test$byClass["F1"], boost_test.cm$byClass["F1"], bag_test.cm$byClass["F1"], rf_test.cm$byClass["F1"], confusionMatrix(outcome_class_test$actual, outcome_class_test$majority_vote, positive="1")$byClass["F1"], confusionMatrix(outcome_prob_test$actual, outcome_prob_test$average_class, positive="1")$byClass["F1"]))
F1
```

```{r fig.height=4, fig.width=7}
acc_melt <- melt(balanced_accuracy, id="model")
ggplot(data=acc_melt, aes(x=reorder(model, -value), y=value, colour=variable))+
  geom_col(position="dodge", fill="grey96")+
  geom_text(aes(label=round(value,3)), vjust=-0.4, position=position_dodge(width=1), cex=2.5)+
  theme_bw()+
  theme(axis.text.x=element_text(angle=60, vjust=0.6))+
  labs(x="Model", title="Balanced accuracy for each method")
```

```{r fig.height=4, fig.width=7}
f1_melt <- melt(F1, id="model")
ggplot(data=f1_melt, aes(x=reorder(model, -value), y=value, colour=variable))+
  geom_col(position="dodge", fill="grey96")+
  geom_text(aes(label=round(value,3)), vjust=-0.4, position=position_dodge(width=1), cex=2.5)+
  theme_bw()+
  theme(axis.text.x=element_text(angle=60, vjust=0.6))+
  labs(x="Model", title="F1 for each method")
```


